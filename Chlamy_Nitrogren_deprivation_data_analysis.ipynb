{
 "metadata": {
  "name": "Chlamy_Nitrogren_deprivation_data_analysis"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "import matplotlib.pyplot as plt\n",
      "sys.path.append('/global/homes/a/apratap/dev/eclipse_workspace/python_scripts/lib/');\n",
      "import utils\n",
      "import os\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def create_data_array_from_mapped_files(file_list):\n",
      "    \n",
      "    SUB = 'create_data_array_from_files'\n",
      "    data = []\n",
      "    \n",
      "    for file_name in file_list:\n",
      "        with open(file_name, 'r') as fh:\n",
      "            file_basename = os.path.basename(file_name)\n",
      "            pattern='^.+?experiment\\/(N_.+?)_([AB]).+?accepted_hits_(.+?)\\.bam\\.alignstats$'\n",
      "            matches = re.search(pattern,file_name)\n",
      "            #print '[%s]: Reading data from file file %s' % (SUB,file_basename)\n",
      "            if matches:\n",
      "                #print matches.group(1)\n",
      "                #print matches.group(2)\n",
      "                #print matches.group(3)\n",
      "                #print '----------------------'\n",
      "                condition=matches.group(1)\n",
      "                replicate=matches.group(2)\n",
      "                strand = matches.group(3)\n",
      "            else:\n",
      "                print '[%s]:Warn: Could not find condition and replicate info'\n",
      "                condition = 'NA'\n",
      "                replicate = 'NA' \n",
      "            \n",
      "            \n",
      "            \n",
      "            for (line_num,line) in enumerate(fh):\n",
      "                \n",
      "                #ignore first 3 lines\n",
      "                if line_num <=2:\n",
      "                    continue\n",
      "                    \n",
      "                (variable,value) = line.strip().split()\n",
      "                if variable == '#primary':\n",
      "                    #print variable,value\n",
      "                    \n",
      "                    data.append([condition,replicate,strand,'primary',value])\n",
      "                    #pass\n",
      "        \n",
      "                if variable == '#secondary':\n",
      "                    #print variable,value\n",
      "                    data.append([condition,replicate,strand,'secondary',value])\n",
      "                    \n",
      "                    \n",
      "            #print data\n",
      "    return data\n",
      "    \n",
      "\n",
      "    \n",
      "def create_data_array_from_unmapped_files(file_list):\n",
      "    \n",
      "    SUB = 'create_data_array_from_unmapped_files'\n",
      "    data = []\n",
      "    \n",
      "    for file_name in file_list:\n",
      "        with open(file_name, 'r') as fh:\n",
      "            file_basename = os.path.basename(file_name)\n",
      "            pattern='^.+?experiment\\/(N_.+?)_([AB]).*$'\n",
      "            matches = re.search(pattern,file_name)\n",
      "            #print '[%s]: Reading data from file file %s' % (SUB,file_name)\n",
      "            if matches:\n",
      "                #print matches.group(1)\n",
      "                #print matches.group(2)\n",
      "                #print matches.group(3)\n",
      "                #print '----------------------'\n",
      "                condition=matches.group(1)\n",
      "                replicate=matches.group(2)\n",
      "                strand = 'NA'\n",
      "            else:\n",
      "                print '[%s]:Warn: Could not find condition and replicate info'\n",
      "                condition = 'NA'\n",
      "                replicate = 'NA' \n",
      "            \n",
      "            \n",
      "            \n",
      "            for (line_num,line) in enumerate(fh):\n",
      "                \n",
      "                #ignore first 3 lines\n",
      "                if line_num <=2:\n",
      "                    continue\n",
      "                    \n",
      "                (variable,value) = line.strip().split()\n",
      "         #       print line\n",
      "                if variable == '#unmapped_reads':\n",
      "          #          print variable,value\n",
      "                    data.append([condition,replicate,strand,'unmapped',value])\n",
      "        #print data_per_file\n",
      "    return data\n",
      "\n",
      "        \n",
      "        \n",
      "        \n",
      "#get the list of all the files to aggregate\n",
      "pattern_mapped_reads = 'accepted*sense*alignstats'\n",
      "bam_files_root_path = '/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/Chlamy_Nitro_deprivation_Project/Chlamydomonas_reinhardtii_4A+_404151/experiment'\n",
      "\n",
      "\n",
      "files = utils.get_FilesList(bam_files_root_path,pattern=pattern_mapped_reads) \n",
      "data_mapped_reads = create_data_array_from_mapped_files(files)\n",
      "print 'Found %d items back' % (len(data_mapped_reads))\n",
      "\n",
      "\n",
      "\n",
      "pattern_unmapped_reads = 'unmapped*alignstats'\n",
      "bam_files_root_path = '/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/Chlamy_Nitro_deprivation_Project/Chlamydomonas_reinhardtii_4A+_404151/experiment'\n",
      "\n",
      "\n",
      "files = utils.get_FilesList(bam_files_root_path,pattern=pattern_unmapped_reads) \n",
      "data_unmapped_reads = create_data_array_from_unmapped_files(files)\n",
      "print 'Found %d items back' % (len(data_unmapped_reads))\n",
      "\n",
      "\n",
      "\n",
      "#getting clean reads per sample\n",
      "\n",
      "\n",
      "raw_reads ='/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/Chlamy_Nitro_deprivation_Project/Chlamydomonas_reinhardtii_4A+_404151/ERCC_mapping/raw_reads_per_sample.txt'\n",
      "\n",
      "data_raw_reads =[ [x.split()[0],x.split()[1],'NA','raw',x.split()[-1]] for (num,x) in enumerate(open(raw_reads,'r')) if num != 0]\n",
      "\n",
      "\n",
      "data = data_mapped_reads + data_unmapped_reads + data_raw_reads\n",
      "\n",
      "df = pandas.DataFrame(data,columns=['condition','replicate','strand','type','count'])\n",
      "\n",
      "\n",
      "print df\n",
      "mapping_summary ='/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/Chlamy_Nitro_deprivation_Project/Chlamydomonas_reinhardtii_4A+_404151/ERCC_mapping/mapping_summary.tsv'\n",
      "df.to_csv(mapping_summary,sep='\\t',index=False)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[get_FilesList]: Found 36 files at /global/projectb/projectdirs/PI/Chlamy_Chia_Lin/Chlamy_Nitro_deprivation_Project/Chlamydomonas_reinhardtii_4A+_404151/experiment\n",
        "Found 72 items back\n",
        "[get_FilesList]: Found 18 files at /global/projectb/projectdirs/PI/Chlamy_Chia_Lin/Chlamy_Nitro_deprivation_Project/Chlamydomonas_reinhardtii_4A+_404151/experiment"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found 18 items back\n",
        "    condition replicate     strand       type      count\n",
        "0        N_0m         A  antisense    primary   62204046\n",
        "1        N_0m         A  antisense  secondary    7975140\n",
        "2        N_0m         A      sense    primary   61019168\n",
        "3        N_0m         A      sense  secondary   11333047\n",
        "4        N_0m         B      sense    primary   95292456\n",
        "5        N_0m         B      sense  secondary   13373556\n",
        "6        N_0m         B  antisense    primary   98772705\n",
        "7        N_0m         B  antisense  secondary   11621667\n",
        "8       N_10m         A      sense    primary   49608856\n",
        "9       N_10m         A      sense  secondary    9202513\n",
        "10      N_10m         A  antisense    primary   51154038\n",
        "11      N_10m         A  antisense  secondary    6774957\n",
        "12      N_10m         B  antisense    primary   46007007\n",
        "13      N_10m         B  antisense  secondary    5551739\n",
        "14      N_10m         B      sense    primary   44224315\n",
        "15      N_10m         B      sense  secondary    6446127\n",
        "16       N_1h         A      sense    primary   54616787\n",
        "17       N_1h         A      sense  secondary    9159943\n",
        "18       N_1h         A  antisense    primary   56714898\n",
        "19       N_1h         A  antisense  secondary    8471861\n",
        "20       N_1h         B  antisense    primary  138079868\n",
        "21       N_1h         B  antisense  secondary   23681824\n",
        "22       N_1h         B      sense    primary  134258833\n",
        "23       N_1h         B      sense  secondary   28062527\n",
        "24      N_24h         A  antisense    primary   56892492\n",
        "25      N_24h         A  antisense  secondary    7117464\n",
        "26      N_24h         A      sense    primary   52965023\n",
        "27      N_24h         A      sense  secondary    7817425\n",
        "28      N_24h         B  antisense    primary   48089160\n",
        "29      N_24h         B  antisense  secondary    5903421\n",
        "30      N_24h         B      sense    primary   45266617\n",
        "31      N_24h         B      sense  secondary    6386022\n",
        "32       N_2h         A      sense    primary   58712421\n",
        "33       N_2h         A      sense  secondary    9581136\n",
        "34       N_2h         A  antisense    primary   61705347\n",
        "35       N_2h         A  antisense  secondary    8660026\n",
        "36       N_2h         B  antisense    primary   70982335\n",
        "37       N_2h         B  antisense  secondary   11518735\n",
        "38       N_2h         B      sense    primary   67946934\n",
        "39       N_2h         B      sense  secondary   12474355\n",
        "40      N_30m         A      sense    primary   63085088\n",
        "41      N_30m         A      sense  secondary   10430735\n",
        "42      N_30m         A  antisense    primary   65225712\n",
        "43      N_30m         A  antisense  secondary    8865565\n",
        "44      N_30m         B      sense    primary   87083911\n",
        "45      N_30m         B      sense  secondary   12149313\n",
        "46      N_30m         B  antisense    primary   90778614\n",
        "47      N_30m         B  antisense  secondary   11351237\n",
        "48      N_48h         A      sense    primary   45694312\n",
        "49      N_48h         A      sense  secondary    6218094\n",
        "50      N_48h         A  antisense    primary   48676793\n",
        "51      N_48h         A  antisense  secondary    5479428\n",
        "52      N_48h         B      sense    primary   40783220\n",
        "53      N_48h         B      sense  secondary    5805254\n",
        "54      N_48h         B  antisense    primary   42976051\n",
        "55      N_48h         B  antisense  secondary    5178664\n",
        "56       N_6h         A  antisense    primary   62318002\n",
        "57       N_6h         A  antisense  secondary    8397774\n",
        "58       N_6h         A      sense    primary   57754671\n",
        "59       N_6h         A      sense  secondary   10234370\n",
        "60       N_6h         B      sense    primary   67813719\n",
        "61       N_6h         B      sense  secondary   13792577\n",
        "62       N_6h         B  antisense    primary   72929354\n",
        "63       N_6h         B  antisense  secondary   10974171\n",
        "64       N_8h         A      sense    primary   41844914\n",
        "65       N_8h         A      sense  secondary    6693241\n",
        "66       N_8h         A  antisense    primary   45359733\n",
        "67       N_8h         A  antisense  secondary    5371446\n",
        "68       N_8h         B  antisense    primary   48345895\n",
        "69       N_8h         B  antisense  secondary    6085482\n",
        "70       N_8h         B      sense    primary   44445628\n",
        "71       N_8h         B      sense  secondary    7334313\n",
        "72       N_0m         A         NA   unmapped    7291355\n",
        "73       N_0m         B         NA   unmapped    9564216\n",
        "74      N_10m         A         NA   unmapped    6552129\n",
        "75      N_10m         B         NA   unmapped    3876929\n",
        "76       N_1h         A         NA   unmapped    8108125\n",
        "77       N_1h         B         NA   unmapped   30212234\n",
        "78      N_24h         A         NA   unmapped    6310537\n",
        "79      N_24h         B         NA   unmapped    5343857\n",
        "80       N_2h         A         NA   unmapped    8125186\n",
        "81       N_2h         B         NA   unmapped   11182571\n",
        "82      N_30m         A         NA   unmapped    8737593\n",
        "83      N_30m         B         NA   unmapped    8928584\n",
        "84      N_48h         A         NA   unmapped    3715938\n",
        "85      N_48h         B         NA   unmapped    3785309\n",
        "86       N_6h         A         NA   unmapped    7726185\n",
        "87       N_6h         B         NA   unmapped    9148915\n",
        "88       N_8h         A         NA   unmapped    3878563\n",
        "89       N_8h         B         NA   unmapped    4087768\n",
        "90       N_0m         A         NA        raw  142845286\n",
        "91       N_0m         B         NA        raw  220941582\n",
        "92      N_10m         A         NA        raw  122929186\n",
        "93      N_10m         B         NA        raw   99819438\n",
        "94      N_30m         A         NA        raw  151539030\n",
        "95      N_30m         B         NA        raw  194029460\n",
        "96       N_1h         A         NA        raw  129109020\n",
        "97       N_1h         B         NA        raw  334231948\n",
        "98       N_2h         A         NA        raw  156011904\n",
        "99       N_2h         B         NA        raw  163852246\n",
        "100      N_6h         A         NA        raw  138511326\n",
        "101      N_6h         B         NA        raw  162069704\n",
        "102      N_8h         A         NA        raw   95650610\n",
        "103      N_8h         B         NA        raw  100741726\n",
        "104     N_24h         A         NA        raw  124011462\n",
        "105     N_24h         B         NA        raw  109200410\n",
        "106     N_48h         A         NA        raw  104185460\n",
        "107     N_48h         B         NA        raw   93643170\n"
       ]
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc = '#raw_reads        72352215'\n",
      "print c.strip().split(q)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plantTFDB_PFAM_hits_file='/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/annotation/chlamy_PlnTFDB/PlnTFDB_PFAM_hits_592035950.txt'\n",
      "plantTFDB_tf_file='/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/annotation/chlamy_PlnTFDB/PlnTFDB_tf_1680431410.txt'\n",
      "\n",
      "def read_chlamy_plantTFdb_TF_info(plantTFDB_PFAM_hits_file,plantTFDB_tf_file):\n",
      "    \n",
      "    protein_id_to_TF_name = {};\n",
      "    \n",
      "    #reading the TF domains\n",
      "    for line in open(plantTFDB_PFAM_hits_file,'r'):\n",
      "        line_split = line.strip().split('\\t')\n",
      "        protein_id = line_split[1]\n",
      "        tf_domain  = line_split[2]\n",
      "        \n",
      "        if protein_id_to_TF_name.get(protein_id) is None:\n",
      "            protein_id_to_TF_name[protein_id] = set([tf_domain])\n",
      "        else:\n",
      "            #add to set\n",
      "            protein_id_to_TF_name[protein_id].add(tf_domain)\n",
      "    \n",
      "    #reading the TF family\n",
      "    for line in open(plantTFDB_tf_file,'r'):\n",
      "        line_split = line.strip().split('\\t')\n",
      "        protein_id = line_split[1]\n",
      "        tf_domain  = line_split[2]\n",
      "        \n",
      "        if protein_id_to_TF_name.get(protein_id) is None:\n",
      "            protein_id_to_TF_name[protein_id] = set([tf_domain])  #like this logic\n",
      "        else:\n",
      "            #add to set\n",
      "            protein_id_to_TF_name[protein_id].add(tf_domain)\n",
      "    \n",
      "    \n",
      "    return protein_id_to_TF_name\n",
      "    \n",
      "protein_id_to_TF_name = read_chlamy_plantTFdb_TF_info(plantTFDB_PFAM_hits_file,plantTFDB_tf_file)\n",
      "\n",
      "\n",
      "\n",
      "#sample output\n",
      "'''\n",
      "protein-id : PFAM-domain, TF-family\n",
      "414959 set(['TRAF', 'BTB'])\n",
      "400305 set(['GNAT', 'Acetyltransf_1', 'zf-MYND'])\n",
      "426843 set(['PLATZ'])\n",
      "142190 set(['C2C2-GATA', 'GATA'])\n",
      "145759 set(['TRAF', 'BTB'])\n",
      "20566 set(['VARL', 'Involucrin'])\n",
      "177225 set(['ACT', 'bHLH', 'HLH'])\n",
      "410707 set(['Response_reg', 'ARR-B', 'G2-like'])\n",
      "193299 set(['SAM_1', 'HisKA', 'Orphans', 'HATPase_c', 'Response_reg', 'Bac_rhodopsin', 'Guanylate_cyc'])\n",
      "187248 set(['RB_A', 'RB', 'RB_B'])\n",
      "377858 set(['Myb_DNA-binding', 'MYB'])\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "\"\\nprotein-id : PFAM-domain, TF-family\\n414959 set(['TRAF', 'BTB'])\\n400305 set(['GNAT', 'Acetyltransf_1', 'zf-MYND'])\\n426843 set(['PLATZ'])\\n142190 set(['C2C2-GATA', 'GATA'])\\n145759 set(['TRAF', 'BTB'])\\n20566 set(['VARL', 'Involucrin'])\\n177225 set(['ACT', 'bHLH', 'HLH'])\\n410707 set(['Response_reg', 'ARR-B', 'G2-like'])\\n193299 set(['SAM_1', 'HisKA', 'Orphans', 'HATPase_c', 'Response_reg', 'Bac_rhodopsin', 'Guanylate_cyc'])\\n187248 set(['RB_A', 'RB', 'RB_B'])\\n377858 set(['Myb_DNA-binding', 'MYB'])\\n\""
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####\n",
      "#Chlamy Differential expression analysis\n",
      "####\n",
      "\n",
      "\n",
      "import sys\n",
      "import re\n",
      "from pysam import Fastafile\n",
      "import fileinput\n",
      "\n",
      "def dna_RevCompliment(seq):\n",
      "    '''given a dna sequence just returns the reverser compliment on the same strand\n",
      "    mainly done to find the sequence of the other strand in the 5' -> 3' direction\n",
      "    '''\n",
      "    rev_seq = seq[::-1]\n",
      "    rev_table = string.maketrans('ACGTacgt','TGCAtgca')\n",
      "    return rev_seq.translate(rev_table)\n",
      "\n",
      "def create_cuff_gene_ref_gene_loopup_table():\n",
      "    '''\n",
      "    create a dict to lookup reference gene names \n",
      "    given a cuff gene name\n",
      "    '''\n",
      "    chlamy_lookup_table_cuff_gene_to_ref_gene = {}\n",
      "    for num,line in enumerate(open('/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/Chlamy_Nitro_deprivation_Project/Chlamydomonas_reinhardtii_4A+_404151/diff_expression/2_with_merged_gtf/cuff_genes_to_ref_gene_names.txt','r')):\n",
      "        line_split=line.strip().split('\\t')\n",
      "        chlamy_lookup_table_cuff_gene_to_ref_gene[line_split[0]] = line_split[1]\n",
      "    return (chlamy_lookup_table_cuff_gene_to_ref_gene)\n",
      "\n",
      "\n",
      "\n",
      "def get_chlamy_gene_function_info():\n",
      "    #reading the function annotation\n",
      "    chlamy_func_annotation_file='/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/annotation/Chlamy_v5/Creinhardtii_v5.3_223_phytozome_functional_annotation.csv'\n",
      "    test_data='/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/annotation/Chlamy_v5/test.data'\n",
      "\n",
      "    chlamy_function_info = {}\n",
      "    for num,line in enumerate(open(chlamy_func_annotation_file,'r')):\n",
      "        if num == 0 :\n",
      "            continue\n",
      "        line_split = line.replace('\"','').strip().split('\\t')\n",
      "        \n",
      "        #skipping lines which only have gene name\n",
      "        if len(line_split) < 2:\n",
      "            #print line_split\n",
      "            continue\n",
      "        \n",
      "       #gene name \n",
      "        if line_split[0]:\n",
      "            gene_name = re.sub('\\.t.*','',line_split[0])\n",
      "       #gene common name\n",
      "        if len(line_split) >= 4 and line_split[3]:\n",
      "            gene_common_name=line_split[3]\n",
      "        else:\n",
      "            gene_common_name='NA' \n",
      "        #defline : col2\n",
      "        if line_split[1]:\n",
      "            gene_defline = line_split[1]\n",
      "        else:\n",
      "            gene_defline = 'NA'\n",
      "        #function : col14\n",
      "        \n",
      "        if len(line_split) >= 14 and line_split[13]:\n",
      "            gene_func = line_split[13]\n",
      "        else:\n",
      "            gene_func = 'NA'\n",
      "        \n",
      "        \n",
      "        #print \"%s \\t %s \\t %s \\t %s\" % (gene_name,gene_common_name,gene_defline,gene_func)\n",
      "        \n",
      "        chlamy_function_info[gene_name] = (gene_defline,gene_func)\n",
      "        chlamy_function_info[gene_common_name] = (gene_defline,gene_func)\n",
      "        \n",
      "    return chlamy_function_info\n",
      "\n",
      "\n",
      "\n",
      "def read_cuff_diff_gene_exp_data(cuff_diff_gene_file,base_condition,test_condition):\n",
      "    cuff_gene_fold_change = {}\n",
      "    for line in open(cuff_diff_gene_file,'r'):\n",
      "        line_split=line.strip().split('\\t')\n",
      "        \n",
      "        if line_split[4].strip() == base_condition and line_split[5].strip() == test_condition:\n",
      "            gene_name = line_split[0].strip()\n",
      "            gene_fold_change = line_split[9].strip()\n",
      "            cuff_gene_fold_change[gene_name]=gene_fold_change\n",
      "    return cuff_gene_fold_change\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def parse_gtf_file(gtf_file):\n",
      "    \"\"\"\n",
      "    given a gtf file as input this function will parse and return a single line\n",
      "    is a generator : yield single parsed gtf entry one at a time\n",
      "    \"\"\"\n",
      "    \n",
      "    #sample_gtf_line (split in 3 lines for display purposes)\n",
      "    #chromosome_1    Cufflinks       exon    20356   20687   .       +       .       \n",
      "    #gene_id \"XLOC_000036\"; transcript_id \"TCONS_00000050\"; exon_number \"1\"; gene_name \"g3\"; oId \n",
      "    #\"PAC:26903463\"; contained_in \"TCONS_00000051\"; nearest_ref \"PAC:26903463\"; class_code \"=\"; tss_id \"TSS41\"; p_id \"P3\";\n",
      "\n",
      "    ##just creating an abtract class/container to hold the values for features of a gtf line\n",
      "    class gtf_line_container(object):\n",
      "        \n",
      "        def __init__(self):\n",
      "            self.chr=None\n",
      "            self.start=None\n",
      "            self.end=None\n",
      "            self.transcript_id=None\n",
      "            self.gene_id=None\n",
      "            self.feature_type=None\n",
      "            self.attributes=None\n",
      "    \n",
      "    for num,line in enumerate(open(gtf_file,'r')):\n",
      "        \n",
      "        line_split = line.strip().split('\\t')\n",
      "        \n",
      "        #instantiate the container\n",
      "        gtf_line = gtf_line_container()\n",
      "        \n",
      "        attributes_split=line_split[8].split(';')\n",
      "        #sample attribute split line\n",
      "        #['gene_id \"XLOC_000001\"', ' transcript_id \"TCONS_00000001\"', ' exon_number \"1\"', ' oId \"CUFF.31.1\"', ' class_code \"u\"', ' tss_id \"TSS1\"', '']\n",
      "        \n",
      "        #gene_id\n",
      "        gene_id=attributes_split[0].split(' ')[1].replace('\"','')\n",
      "        \n",
      "        #transcrpit_id\n",
      "        transcript_id=attributes_split[1].split(' ')[2].replace('\"','')\n",
      "        \n",
      "        \n",
      "        gtf_line.chr=line_split[0].strip()\n",
      "        gtf_line.start=line_split[3].strip()\n",
      "        gtf_line.end=line_split[4].strip()\n",
      "        gtf_line.strand=line_split[6].strip()\n",
      "        gtf_line.feature_type=line_split[2].strip()\n",
      "        gtf_line.gene_id = gene_id\n",
      "        gtf_line.transcript_id = transcript_id\n",
      "        gtf_line.attributes = attributes_split\n",
      "        yield gtf_line\n",
      "    \n",
      "\n",
      "\n",
      "def summarize_cuffmerge_output(merged_gtf_file,summarize_by=None):\n",
      "    '''\n",
      "    given a merged.gtf file produced by cuffmerge this method can\n",
      "    summarize it by gene or transcript level\n",
      "    **PS: assumption is that for each gene the exons are reported, sorted by position**\n",
      "    variable : summarize_by can take the value of gene,transcript\n",
      "    '''\n",
      "    \n",
      "    \n",
      "    features = {}\n",
      "    \n",
      "    class feature(object):\n",
      "        \n",
      "        def __init__(self):\n",
      "            self.gene_id = None\n",
      "            self.transcript_id = None\n",
      "            self.start = None\n",
      "            self.end = None\n",
      "            self.strand = None\n",
      "            self.attributes = None\n",
      "            \n",
      "    #default for each feature\n",
      "    last_feature_id = None\n",
      "    feature_start = 0;\n",
      "    feature_chromosome = 'NA';\n",
      "    feature_end = 0;\n",
      "    feature_strand = 0;\n",
      "    \n",
      "    \n",
      "    #setting the right feture name\n",
      "    if summarize_by == 'gene':\n",
      "        feature_name = 'gene_id'\n",
      "    elif summarize_by == 'transcript':\n",
      "        feature_name = 'transcript_id'\n",
      "    else: \n",
      "        sys.stderr('Error : not a recognized summarize_by id %s ' % summarize_by)\n",
      "        sys.exit(2)\n",
      "    \n",
      "    \n",
      "    \n",
      "    for gtf_line in parse_gtf_file(merged_gtf_file):\n",
      "            \n",
      "            #interesting peice of logic\n",
      "            #depending on the user entered summarize_by varibale either the transcript_id or gene_id is used\n",
      "            this_feature_id=eval('gtf_line.%s' % feature_name)\n",
      "        \n",
      "            \n",
      "            #initialization\n",
      "            if ( last_feature_id is None):\n",
      "                last_feature_id = this_feature_id\n",
      "                feature_start = gtf_line.start\n",
      "                feature_end   = gtf_line.end\n",
      "                feature_strand = gtf_line.strand\n",
      "                feature_chromosome = gtf_line.chr\n",
      "                continue\n",
      "            \n",
      "            #if we see the same feature, just update the end\n",
      "            if ( last_feature_id == this_feature_id):\n",
      "                feature_end   = gtf_line.end\n",
      "                \n",
      "            else:\n",
      "                #create the new feature summary object before updating to the new feature\n",
      "                feature_summary = feature()\n",
      "                feature_summary.feature_id = last_feature_id\n",
      "                feature_summary.start = feature_start\n",
      "                feature_summary.end = feature_end\n",
      "                feature_summary.strand = feature_strand\n",
      "                feature_summary.chr = feature_chromosome\n",
      "                \n",
      "                #store the feature summary object in a dict\n",
      "                features[last_feature_id] = feature_summary\n",
      "                \n",
      "                ##now update and store the new feature\n",
      "                last_feature_id = this_feature_id\n",
      "                feature_start = gtf_line.start\n",
      "                feature_end   = gtf_line.end\n",
      "                feature_strand = gtf_line.strand\n",
      "                feature_chromosome = gtf_line.chr\n",
      "    \n",
      "    \n",
      "    feature_summary = feature()\n",
      "    feature_summary.feature_id = last_feature_id\n",
      "    feature_summary.start = feature_start\n",
      "    feature_summary.end = feature_end\n",
      "    feature_summary.strand = feature_strand\n",
      "    feature_summary.chr = feature_chromosome\n",
      "                \n",
      "    #store the feature summary object in a dict\n",
      "    features[last_feature_id] = feature_summary\n",
      "    \n",
      "    print 'Created features dict, summarized by %s of len %d' % (summarize_by,len(features))\n",
      "    return (features)\n",
      " \n",
      "  \n",
      "    \n",
      "        \n",
      "        \n",
      "cuffmerge_gtf_file = '/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/Chlamy_Nitro_deprivation_Project/Chlamydomonas_reinhardtii_4A+_404151/assembly/cuffmerge_with_reference_annotation/merged_asm/merged.gtf'\n",
      "cuffmerge_gtf_file_test = '/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/Chlamy_Nitro_deprivation_Project/Chlamydomonas_reinhardtii_4A+_404151/assembly/cuffmerge_with_reference_annotation/merged_asm/test.gtf'\n",
      "\n",
      "#dict of cuff gene names poiting to class object which stores start,end,strand,chr\n",
      "cuff_genes_coords = summarize_cuffmerge_output(cuffmerge_gtf_file,summarize_by='gene')\n",
      "\n",
      "#dict of cuff gene to ref_gene name\n",
      "cuff_gene_name_to_ref_gene_lookUP = create_cuff_gene_ref_gene_loopup_table()\n",
      "\n",
      "#dict of ref_gene to annotated function\n",
      "chlamy_gene_function_info = get_chlamy_gene_function_info()\n",
      "\n",
      "#chlamy diff genes file\n",
      "chlamy_diff_exp_gene_file='/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/Chlamy_Nitro_deprivation_Project/Chlamydomonas_reinhardtii_4A+_404151/diff_expression/2_with_merged_gtf/gene_exp.diff'\n",
      "cuff_gene_fold_change = read_cuff_diff_gene_exp_data(chlamy_diff_exp_gene_file,'N_0m','N_10m')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Created features dict, summarized by gene of len 14418\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DE_gene_list_0_10m = '/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/Chlamy_Nitro_deprivation_Project/Chlamydomonas_reinhardtii_4A+_404151/diff_expression/2_with_merged_gtf/genes_DE_0_10m.txt'\n",
      "DE_gene_list_0_30m = '/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/Chlamy_Nitro_deprivation_Project/Chlamydomonas_reinhardtii_4A+_404151/diff_expression/2_with_merged_gtf/genes_DE_0_30m.txt'\n",
      "\n",
      "\n",
      "chlamy_v5_genome='/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/reference/Chlamy_V5/C_reinhardtii.110311_Chlroplast_mitochondira/Chlre5_genomic_scaffold_plastids.fasta'\n",
      "chlamy_v5_genome_fasta = Fastafile(chlamy_v5_genome)\n",
      "\n",
      "de_genes_list_file = DE_gene_list_0_10m\n",
      "fout1 = open(de_genes_list_file+'.function','w')\n",
      "fout2 = open(de_genes_list_file+'.fasta','w')\n",
      "\n",
      "total_cuff_DE_genes_up_regulated =0\n",
      "total_cuff_DE_genes_down_regulated =0\n",
      "count_novel_DE_genes = 0\n",
      "\n",
      "#read the DE genes \n",
      "for num,line in enumerate(open(de_genes_list_file,'r')):\n",
      "    cuff_gene_name = line.strip();\n",
      "    \n",
      "    \n",
      "    #following blob to create a fasta which could be blasted against the PltTFD TF protein sequences to find possible matches\n",
      "    if cuff_genes_coords[cuff_gene_name]:\n",
      "        #access the gene feature object\n",
      "        gf = cuff_genes_coords[cuff_gene_name]\n",
      "        #fetching the fastq from the Chlamy_v5_genome\n",
      "        gene_seq = chlamy_v5_genome_fasta.fetch(gf.chr,int(gf.start),int(gf.end)).strip()\n",
      "        fout2.write('>%s_chr:%s_start:%s_end:%s_strand:%s\\n%s\\n' %(cuff_gene_name,gf.chr,gf.start,gf.end,gf.strand,gene_seq))\n",
      "    else:\n",
      "        print 'Warn not found the coords for %s gene' % cuff_gene_name\n",
      "    \n",
      "\n",
      "    #get the chlamy ref gene name\n",
      "    ref_gene_name=cuff_gene_name_to_ref_gene_lookUP.get(cuff_gene_name)\n",
      "    \n",
      "    #get the fold enrichment\n",
      "    gene_fold_change = cuff_gene_fold_change.get(cuff_gene_name)\n",
      "    if gene_fold_change is None:\n",
      "        gene_fold_change = 0.0\n",
      "    elif float(gene_fold_change) > 0:\n",
      "        gene_regulation = 'up'\n",
      "        total_cuff_DE_genes_up_regulated += 1\n",
      "    else:\n",
      "        gene_regulation='down'\n",
      "        total_cuff_DE_genes_down_regulated += 1\n",
      "    \n",
      "    \n",
      "    #getting the function for ref_gene based on \n",
      "    for each_ref_gene in ref_gene_name.split(','):\n",
      "        gene_function = chlamy_gene_function_info.get(each_ref_gene)\n",
      "        if gene_function is not None:\n",
      "           gene_function_line=''.join(gene_function).replace('NA','')\n",
      "        else:\n",
      "            gene_function_line='NA'\n",
      "        \n",
      "        #novel gene that is differentially expressed\n",
      "        if ref_gene_name == '-':\n",
      "            count_novel_DE_genes += 1\n",
      "            gene_function_line = 'novel-gene'\n",
      "            \n",
      "        fout1.write('%s \\t %s \\t %s \\t %s \\t %s \\n' % (cuff_gene_name, each_ref_gene,gene_regulation,str(gene_fold_change),gene_function_line))\n",
      "        \n",
      "    \n",
      "fout1.close()\n",
      "fout2.close()\n",
      "print '#cuff DE genes: %d' % (num+1)\n",
      "print '#up-regulated: %d' % (total_cuff_DE_genes_up_regulated) \n",
      "print '#down-regulated: %d' % (total_cuff_DE_genes_down_regulated)\n",
      "print '#novel DE genes: %d' % (count_novel_DE_genes)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#cuff DE genes: 1607\n",
        "#up-regulated: 700\n",
        "#down-regulated: 907\n",
        "#novel DE genes: 31\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}