{
 "metadata": {
  "name": "ChIA-PET"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pysam\n",
      "import pybedtools\n",
      "import matplotlib.pyplot as plt\n",
      "import math\n",
      "import os\n",
      "import sys\n",
      "import pybedtools\n",
      "import itertools\n",
      "import pprint\n",
      "from time import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sys.path.append('/global/homes/a/apratap/dev/eclipse_workspace/python_scripts/lib');\n",
      "import bamUtils"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#non stranded uniq_1.5kb+/- extended region\n",
      "#mm9 non-stranded Uniq regions bucket\n",
      "#formed by extending mm9 reads (outside TSS) by 1.5kb on each direction\n",
      "uniq_extended_non_stranded_region_file='/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/mouse_ChIA_PET/CAZH/3.map_with_std_bowtie2/bowtie2_map_manual_pair/test_end_to_end_mapping/association_analysis/uniq_clustered_regions_outside_TSS_reads_extended_1.5kb_merged.txt'\n",
      "num_extended_reads_per_uniq_region = [ math.log10(int(x.split('\\t')[4])) for x in open(uniq_extended_non_stranded_region_file,'r')]\n",
      "print 'read %d points from the file'  % len(num_extended_reads_per_uniq_region)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "read 85439 points from the file\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(num_extended_reads_per_uniq_region,bins=100,color='lightgreen')\n",
      "plt.xlabel('num of extended reads per uniq region(log10)')\n",
      "plt.ylabel('frequency')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#####\n",
      "#input 1.\n",
      "    #TSS - read mapping file\n",
      "    #building the hash to store read info reads falling in the TSS region\n",
      "\n",
      "\n",
      "reads_to_tss_region_mapping_file='/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/mouse_ChIA_PET/CAZH/3.map_with_std_bowtie2/bowtie2_map_manual_pair/test_end_to_end_mapping/association_analysis/test/reads_matched_to_TSS_region.txt'\n",
      "\n",
      "\n",
      "#dictionary to hold the read connections between TSS and UR regions\n",
      "read_connections = {}\n",
      "\n",
      "count_TSS_to_TSS_connections = 0\n",
      "\n",
      "\n",
      "for count,row in enumerate(open(reads_to_tss_region_mapping_file,'r')):\n",
      "    if count == 100:\n",
      "        pass\n",
      "    \n",
      "    split_row = row.split('\\t')\n",
      "    read_header=split_row[3][:-2].strip()\n",
      "    read_type=split_row[3][-1].strip()\n",
      "    tss_chr=split_row[12].strip()\n",
      "    tss_start=split_row[13].strip()\n",
      "    tss_end=split_row[14].strip()\n",
      "    \n",
      "    #new read\n",
      "    if read_connections.get(read_header,None) is None:\n",
      "        read_connections[read_header]={}\n",
      "        read_connections[read_header][read_type] = [('tss',tss_chr,tss_start,tss_end)]\n",
      "    else:\n",
      "        #possible that mate of the read maps to some TSS region\n",
      "        #so most likely this read should be the mate, if not somethng is going on\n",
      "        if read_connections[read_header].get(read_type,None) is None:\n",
      "            #this is the mate\n",
      "            read_connections[read_header][read_type] = [('tss',tss_chr,tss_start,tss_end)]\n",
      "            count_TSS_to_TSS_connections += 1\n",
      "        else:\n",
      "            #seeing the same read  header and read_type again\n",
      "            #most likely some issue as same read in this data should not be mapped to more than one place on TSS\n",
      "            print 'Warning : Read %s is seen twice' % read_header\n",
      "            #print 'First seen at %s' % pprint.pprint(read_connections[read_header])\n",
      "            continue\n",
      "\n",
      "    #print mapped_read_header,tss_chr,tss_start,tss_end,read_type\n",
      "    \n",
      "print 'Read %d reads in the file' % count\n",
      "print '%d fragments present' % len(read_connections)\n",
      "print '%d TSS_to_TSS connections' % count_TSS_to_TSS_connections\n",
      "\n",
      "\n",
      "\n",
      "#adding the connections to TSS read\n",
      "#approach 2 : Oct 4, 2012\n",
      "#adding the connection of the mate found in the above code/cell(inside the TSS region)\n",
      "clustered_region_file = '/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/mouse_ChIA_PET/CAZH/3.map_with_std_bowtie2/bowtie2_map_manual_pair/test_end_to_end_mapping/association_analysis/uniq_clustered_regions_outside_TSS_reads_extended_1.5kb_merged.txt'\n",
      "\n",
      "\n",
      "count_UR_read_fragment_NOT_seen_in_TSS = 0\n",
      "count_UR_read_fragment_seen_in_TSS = 0\n",
      "TSS_to_UR_connection = 0\n",
      "possible_errors = 0\n",
      "total_reads = 0\n",
      "\n",
      "for count,row in enumerate(open(clustered_region_file,'r')):\n",
      "    if count == 10000:\n",
      "        pass\n",
      "        #break\n",
      "    \n",
      "    split_row = row.split('\\t')\n",
      "    UR_chr=split_row[0].strip()\n",
      "    UR_start=split_row[1].strip()\n",
      "    UR_end=split_row[2].strip()\n",
      "    reads_in_UR_bundle = split_row[3].strip().split(';')\n",
      "    num_reads_in_UR = split_row[4].strip()\n",
      "    \n",
      "    \n",
      "    if len(reads_in_UR_bundle) != int(num_reads_in_UR):\n",
      "        #we have a problem\n",
      "        #num of reads merged by bedtools is not same the reported number of reads merged\n",
      "        print 'error:num of reads merged by bedtools is not same the reported number of reads merged'\n",
      "        sys.exit()\n",
      "    \n",
      "    \n",
      "    total_reads += int(num_reads_in_UR)\n",
      "    #print UR_chr,UR_start,UR_end,len(reads_in_UR),num_reads_in_UR\n",
      "    #iterate over bundle of reads in UR and establish connections with TSS\n",
      "    UR_name = 'UR-%d' % count\n",
      "    UR_bundle=(UR_name,UR_chr,UR_start,UR_end)\n",
      "    \n",
      "    for reads in reads_in_UR_bundle:\n",
      "        read_header=reads[:-2].strip()\n",
      "        read_type=reads[-1].strip()\n",
      "        #print read_header, read_type\n",
      "        \n",
      "    \n",
      "        #new read which was not seen in the TSS data : discard\n",
      "        if read_connections.get(read_header,None) is None:\n",
      "            count_UR_read_fragment_NOT_seen_in_TSS += 1\n",
      "            continue\n",
      "        else:\n",
      "            #read was seen in the TSS data, whether same read or its mate we will check\n",
      "            count_UR_read_fragment_seen_in_TSS += 1\n",
      "            \n",
      "        #TSS-TSS interactions should be captured already while reading reads mapped to TSS\n",
      "        #what would be interesting to look at is the pairs which have one mate in TSS but other in UR (which is not in TSS)\n",
      "        #so any read which already has its two mate accounted for in TSS comparison above is not useful for our comparison\n",
      "        \n",
      "            if len(read_connections[read_header].keys()) == 2:\n",
      "                #i.e both the reads have been seen interacting within a TSS region\n",
      "                #skip\n",
      "                #possible error : these regions are coming from reads falling outside TSS\n",
      "                print 'we already seen both mates of the read before %s, %s' % (read_header,UR_bundle)\n",
      "                possible_errors += 1\n",
      "                pprint.pprint(read_connections[read_header])\n",
      "                continue\n",
      "            \n",
      "            if read_connections[read_header].get(read_type,None) is None:\n",
      "                #found a read whose mate was mapped to TSS and other mate is in the UR region\n",
      "                TSS_to_UR_connection += 1\n",
      "                read_connections[read_header][read_type] = [('UR',UR_chr,UR_start,UR_end)]\n",
      "                \n",
      "                #print 'Found the mate of the read that was mapped to TSS in a UR' \n",
      "                #print 'read_header %s' % read_header\n",
      "                #print 'Initial structure' \n",
      "                #pprint.pprint(read_connections[read_header])\n",
      "                #print 'After adding the read structure' \n",
      "                #pprint.pprint(read_connections[read_header])\n",
      "                continue\n",
      "        \n",
      "            else:\n",
      "                #same read was seen in TSS and now found in UR\n",
      "                print 'same read was seen in TSS and now found in UR'\n",
      "                pprint.pprint(read_connections[read_header][read_type])\n",
      "                \n",
      "        \n",
      "    \n",
      "print 'Read %d Uniq Region clusters outside TSS with #reads %d' % (count,total_reads)\n",
      "print 'Count UR fragment seen in TSS %d' % count_UR_read_fragment_seen_in_TSS\n",
      "print 'Count UR fragment NOT seen in TSS %d' % count_UR_read_fragment_NOT_seen_in_TSS\n",
      "print 'count_TSS_to_UR : %d ' % TSS_to_UR_connection\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning : Read HISEQ07:212:C0UVKACXX:1:2201:9740:37843 is seen twice\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:1101:7891:134182 is seen twice"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:1107:18714:165330 is seen twice\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:1106:18202:4722 is seen twice"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:2202:5120:57705 is seen twice"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:1101:12459:112786 is seen twice\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:2106:9519:101259 is seen twice"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:1104:8175:119967 is seen twice"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:1206:5605:152419 is seen twice\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:1208:6376:21375 is seen twice\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:1303:4977:88014 is seen twice\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:1305:16856:158065 is seen twice\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:1307:6690:21367 is seen twice\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:2108:3804:196784 is seen twice\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:2207:1242:151818 is seen twice\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:2208:13470:198097 is seen twice\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:2306:1385:131169 is seen twice\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:2307:1759:159729 is seen twice\n",
        "Warning : Read HISEQ07:212:C0UVKACXX:1:1308:8852:151758 is seen twice"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Read 545593 reads in the file"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "521374 fragments present\n",
        "24201 TSS_to_TSS connections\n",
        "Read 85438 Uniq Region clusters outside TSS with #reads 7185689"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Count UR fragment seen in TSS 497173\n",
        "Count UR fragment NOT seen in TSS 6688516\n",
        "count_TSS_to_UR : 497173 \n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sanity checking the read_connections dict\n",
      "\n",
      "print len(read_connections.keys())\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "521374\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##summarizing read_interactions/connections\n",
      "\n",
      "interactions = {}\n",
      "count_TSS_to_TSS_interactions = 0\n",
      "count_TSS_to_UR_interactions = 0\n",
      "count_UR_to_UR_interactions = 0\n",
      "\n",
      "for count,read in enumerate(read_connections):\n",
      "    \n",
      "    if count == 100:\n",
      "        pass\n",
      "    \n",
      "    if len(read_connections[read]) <= 1:\n",
      "        print 'Read mapped only to TSS/UR region'\n",
      "        pprint.pprint(read_connections[read])\n",
      "        #possible error or only one read was found to be mapped between TSS and UR region\n",
      "        pass\n",
      "        \n",
      "    else:\n",
      "        read_1_map = read_connections[read]['1']\n",
      "        read_2_map = read_connections[read]['2']\n",
      "        \n",
      "        #determine the mate which maps to tss, if both fall on tss doesn't matter\n",
      "        read_1_map_region = read_1_map[0][0]\n",
      "        read_2_map_region = read_2_map[0][0]\n",
      "        \n",
      "        #print read\n",
      "        #print pprint.pprint(read_connections[read])\n",
      "        #print 'Read1_map_region : %s' % read_1_map_region\n",
      "        #print 'Read2_map_region : %s' % read_2_map_region\n",
      "        \n",
      "        interaction_start = None\n",
      "        intertation_end   = None\n",
      "        \n",
      "        if read_1_map_region == 'tss' and read_2_map_region == 'tss':\n",
      "            #print 'tss_to_tss'\n",
      "            count_TSS_to_TSS_interactions +=1\n",
      "            interaction_start = read_1_map\n",
      "            interaction_end = read_2_map\n",
      "        \n",
      "        elif read_1_map_region == 'tss' and read_2_map_region == 'UR':\n",
      "            #print 'tss_to_UR'\n",
      "            count_TSS_to_UR_interactions +=1\n",
      "            interaction_start = read_1_map\n",
      "            interaction_end = read_2_map\n",
      "        \n",
      "        elif read_1_map_region == 'UR' and read_2_map_region == 'tss':\n",
      "            #print 'UR_to_tss'\n",
      "            count_TSS_to_UR_interactions +=1\n",
      "            interaction_start = read_2_map   #here read2 becomes the interaction start as it is coming from tss region\n",
      "            interaction_end = read_1_map\n",
      "        \n",
      "        elif read_1_map_region == 'UR' and read_2_map_region == 'UR':\n",
      "            count_UR_to_UR_interactions +=1\n",
      "            continue\n",
      "            \n",
      "        else:\n",
      "            print 'left over case'\n",
      "            print read_1_map_region,read_2_map_region\n",
      "            continue\n",
      "        \n",
      "        \n",
      "      \n",
      "        #print 'START', interaction_start   #sample [('tss', 'chr9', '117947116', '117952116')]\n",
      "        #print 'END' ,interaction_end   #sample [('tss', 'chr9', '117947116', '117952116')]\n",
      "        #print '--------'\n",
      "    \n",
      "    \n",
      "        istart_region = interaction_start[0][0]\n",
      "        istart_chr = interaction_start[0][1]\n",
      "        istart_start = interaction_start[0][2]\n",
      "        istart_end = interaction_start[0][3]\n",
      "        \n",
      "        \n",
      "        iend_region = interaction_end[0][0]\n",
      "        iend_chr = interaction_end[0][1]\n",
      "        iend_start = interaction_end[0][2]\n",
      "        iend_end = interaction_end[0][3]\n",
      "        \n",
      "\n",
      "        interaction_start_key = '%s-%s:%s-%s' % (istart_region,istart_chr,istart_start,istart_end)\n",
      "        interaction_end_key = '%s-%s:%s-%s' % (iend_region,iend_chr,iend_start,iend_end)\n",
      "        \n",
      "        #classify interaction to cis/trans\n",
      "        interaction_type = None\n",
      "        if istart_chr is not None and iend_chr is not None:\n",
      "            \n",
      "            if istart_chr == iend_chr:\n",
      "                interaction_type = 'cis'\n",
      "            else:\n",
      "                interaction_type = 'trans'\n",
      "        else:\n",
      "            print 'region empty'\n",
      "                                                                            \n",
      "        \n",
      "        if interactions.get(interaction_start_key,None) is None:\n",
      "            #new tss region\n",
      "            interactions[interaction_start_key]={}\n",
      "            interactions[interaction_start_key][interaction_end_key] = {}\n",
      "            interactions[interaction_start_key][interaction_end_key]['count'] = 1\n",
      "            interactions[interaction_start_key][interaction_end_key]['type'] = interaction_type\n",
      "            \n",
      "            \n",
      "        else:\n",
      "            #tss region seen before\n",
      "            if interactions[interaction_start_key].get(interaction_end_key,None) is None:\n",
      "                #new connection from the TSS region or interaction_start\n",
      "                interactions[interaction_start_key][interaction_end_key] = {}\n",
      "                interactions[interaction_start_key][interaction_end_key]['count'] = 1\n",
      "                interactions[interaction_start_key][interaction_end_key]['type'] = interaction_type\n",
      "                \n",
      "            #seeing the same interaction again\n",
      "            else:\n",
      "                interactions[interaction_start_key][interaction_end_key]['count'] += 1\n",
      "            \n",
      "\n",
      "print 'total read fragments processed %d ' % (count)\n",
      "print 'total TSS_to_TSS connection (non-unique) %d' % ( count_TSS_to_TSS_interactions)\n",
      "print 'total TSS_to_UR connection (non-unique) %d' % ( count_TSS_to_UR_interactions)\n",
      "print 'total UR_to_UR connection %d' % ( count_UR_to_UR_interactions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total read fragments processed 521373 \n",
        "total TSS_to_TSS connection (non-unique) 24201\n",
        "total TSS_to_UR connection (non-unique) 497173\n",
        "total UR_to_UR connection 0\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#filtering the interactions\n",
      "#removing all interactions which have 1 connection\n",
      "\n",
      "test_interactions = '/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/mouse_ChIA_PET/CAZH/3.map_with_std_bowtie2/bowtie2_map_manual_pair/test_end_to_end_mapping/association_analysis/test/test_interactions.txt'\n",
      "out_fh= open(test_interactions,'w')\n",
      "\n",
      "\n",
      "num_connections_per_interaction= []\n",
      "num_connections_per_cis_interaction= []\n",
      "num_connections_per_trans_interaction= []\n",
      "interaction_end_span = []\n",
      "cis_interaction_end_span = []\n",
      "trans_interaction_end_span = []\n",
      "\n",
      "total_number_of_interactions = 0\n",
      "num_interactions_with_gt_on_connections = 0\n",
      "num_interactions_with_one_connection = 0\n",
      "num_interactions_within_same_TSS = 0\n",
      "num_interactions_within_UR_regions_to_skip = 0\n",
      "num_interactions_with_random_chr = 0\n",
      "\n",
      "UR_regions_to_skip= ['UR-chr2:98488669-98582733','UR-chr9:2998474-3037668']\n",
      "\n",
      "for count,interaction_start in enumerate(interactions.keys()):\n",
      "    if count == 2:\n",
      "        #break\n",
      "        pass   \n",
      "    #pprint.pprint(interactions[interaction_start])\n",
      "\n",
      "    for interaction_end in interactions[interaction_start].keys():\n",
      "        num_of_connections = interactions[interaction_start][interaction_end]['count']\n",
      "        interaction_type = interactions[interaction_start][interaction_end]['type']\n",
      "        \n",
      "        \n",
      "        total_number_of_interactions += 1\n",
      "        #print interaction_start,interaction_end,num_of_connections,interaction_type\n",
      "        \n",
      "        \n",
      "        if num_of_connections > 1:\n",
      "            \n",
      "            num_interactions_with_gt_on_connections += 1\n",
      "        \n",
      "        \n",
      "            if interaction_start == interaction_end:\n",
      "                num_interactions_within_same_TSS += 1\n",
      "                continue\n",
      "            \n",
      "            elif interaction_end in UR_regions_to_skip:\n",
      "                num_interactions_within_UR_regions_to_skip += 1\n",
      "                continue\n",
      "                \n",
      "            elif interaction_start.find('random') != -1 or interaction_end.find('random') != -1:\n",
      "                num_interactions_with_random_chr += 1\n",
      "                continue\n",
      "            \n",
      "            else:\n",
      "                #print interaction_end\n",
      "                temp_list = interaction_end.split(':')[1].split('-')\n",
      "                span_size = int(temp_list[1])-int(temp_list[0])\n",
      "                interaction_end_span.append(math.log10(span_size))\n",
      "        \n",
      "    \n",
      "            #check if the interaction type\n",
      "            if interaction_type == 'cis':\n",
      "                num_connections_per_cis_interaction.append(math.log(num_of_connections,2))\n",
      "                cis_interaction_end_span.append( math.log10(span_size))\n",
      "            elif interaction_type == 'trans':\n",
      "                num_connections_per_trans_interaction.append(math.log(num_of_connections,2))\n",
      "                trans_interaction_end_span.append( math.log10(span_size))\n",
      "            else:\n",
      "                print 'Error cant determine connection type'\n",
      "            \n",
      "            \n",
      "            num_connections_per_interaction.append(math.log(num_of_connections,2)) #for plotting the #interactions > 1 \n",
      "            line = '%s \\t  %s \\t %s \\t %s\\n' % (interaction_start,interaction_end,num_of_connections,interaction_type)\n",
      "            out_fh.write(line)\n",
      "        else:\n",
      "            num_interactions_with_one_connection += 1\n",
      "        \n",
      "        \n",
      "        \n",
      "            \n",
      "print 'Total number of interactions: %d' % (total_number_of_interactions)\n",
      "print 'number of interactions with >1 connections %d' % (num_interactions_with_gt_on_connections)\n",
      "print 'number of interactions within same TSS %d' % (num_interactions_within_same_TSS)\n",
      "print 'number of interactions in skipped regions %d' % (num_interactions_within_UR_regions_to_skip)\n",
      "print 'number of interactions involving random chrs %d' % (num_interactions_with_random_chr)\n",
      "print 'number of cis interactions in filtered connections %d' % len(num_connections_per_cis_interaction)\n",
      "print 'number of trans interactions in filtered connections %d' % len(num_connections_per_trans_interaction)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total number of interactions: 460519\n",
        "number of interactions with >1 connections 23044\n",
        "number of interactions within same TSS 867\n",
        "number of interactions in skipped regions 11539\n",
        "number of interactions involving random chrs 645\n",
        "number of cis interactions in filtered connections 1402\n",
        "number of trans interactions in filtered connections 8591\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plotting the summary numbers\n",
      "#plt.hist(num_connections_per_interaction,color='#7FC97F',bins=50,label='all_connections')\n",
      "plt.hist(num_connections_per_trans_interaction,color='black',bins=50,label='trans')\n",
      "plt.hist(num_connections_per_cis_interaction,color='lightgreen',bins=50,label='cis')\n",
      "plt.xlabel('number of connections per interaction(log2 scale)')\n",
      "plt.ylabel('frequency')\n",
      "plt.legend()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(interaction_end_span,bins=50,color='#1B9E77',label='span_all_end_points')\n",
      "plt.hist(trans_interaction_end_span,bins=50,color='#D95F02',label='span_trans')\n",
      "plt.hist(cis_interaction_end_span,bins=50,color='#7570B3',label='span_cis')\n",
      "plt.legend()\n",
      "plt.ylabel('frequency')\n",
      "plt.xlabel('Span size of connections from TSS regions(log10 scale)')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_bedtool_object_for_read(read,bamFile_handle):\n",
      "    bed_interval='%s %s %s %s' % (bamFile_handle.getrname(read.tid),read.mpos,read.mpos+read.rlen,read.qname)\n",
      "    return (pybedtools.BedTool(bed_interval,from_string=True))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "\n",
      "#mm9 uniq non stranded TSS bucket\n",
      "tss_file = '/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/annotation/mm9/mm9_genes_TSS_+-2.5kb_uniq_region_non_stranded.bed'\n",
      "\n",
      "\n",
      "test_chr4_only_bamFile = '/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/mouse_ChIA_PET/CAZH/3.map_with_std_bowtie2/bowtie2_map_manual_pair/test_end_to_end_mapping/association_analysis/test/chr4.bam'\n",
      "\n",
      "#mm9 ChIA-PET mapped data (merged,linker cleaned, split,mapped,paired, duplicates removed)\n",
      "mm9_ChIA_PET_bamfile = '/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/mouse_ChIA_PET/CAZH/3.map_with_std_bowtie2/bowtie2_map_manual_pair/test_end_to_end_mapping/inter_N_intra_rdup_reads.bam'\n",
      "\n",
      "#name sort the bam file\n",
      "mm9_ChIA_PET_name_sorted_bamFile = bamUtils.name_sort_bam(mm9_ChIA_PET_bamfile)\n",
      "print mm9_ChIA_PET_name_sorted_bamFile\n",
      "\n",
      "\n",
      "#open the file handle to bamfile\n",
      "bamFile_handle = pysam.Samfile(mm9_ChIA_PET_name_sorted_bamFile,'rb')\n",
      "\n",
      "\n",
      "tss_file_bedtool = pybedtools.BedTool(tss_file)\n",
      "uniq_region_bedtool = pybedtools.BedTool(uniq_extended_non_stranded_region_file)\n",
      "\n",
      "\n",
      "count_no_TSS_hits = 0\n",
      "count_TSS_hits =0\n",
      "\n",
      "start = time()\n",
      "for (count,read1,read2) in itertools.izip(itertools.count(1),bamFile_handle,bamFile_handle):\n",
      "    \n",
      "    \n",
      "    #sanity check for pairing\n",
      "    if read1.qname != read2.qname:\n",
      "        print 'Error: input bam file doesnt seem to be sorted by read name'\n",
      "        print 'read1 : %s ' % read1\n",
      "        print 'read1 : %s ' % read2\n",
      "        break\n",
      "    \n",
      "    \n",
      "    bedtool_read1 = get_bedtool_object_for_read(read1,bamFile_handle)\n",
      "    bedtool_read2 = get_bedtool_object_for_read(read2,bamFile_handle)\n",
      "    \n",
      "    \n",
      "    read_1_tss_hits = tss_file_bedtool.intersect(bedtool_read1)\n",
      "    read_2_tss_hits = tss_file_bedtool.intersect(bedtool_read2)\n",
      "    \n",
      "    if len(read_1_tss_hits) == 0 and len(read_2_tss_hits) == 0:\n",
      "        count_no_TSS_hits += 1\n",
      "    else:\n",
      "        count_TSS_hits += 1\n",
      "    \n",
      "    \n",
      "    print 'read 1'\n",
      "    print bedtool_read1\n",
      "    print 'UR',uniq_region_bedtool.intersect(bedtool_read1)\n",
      "    print 'read 2'\n",
      "    print bedtool_read2\n",
      "    print 'TSS',tss_file_bedtool.intersect(bedtool_read2)\n",
      "    print 'UR',uniq_region_bedtool.intersect(bedtool_read2)\n",
      "    print '---------------------'\n",
      "    \n",
      "    \n",
      "\n",
      "    if count == 1000000:\n",
      "        print 'processed %d pairs' % count\n",
      "        \n",
      "    \n",
      "    if count == 1000:\n",
      "        break\n",
      "    \n",
      "    \n",
      "stop = time()\n",
      "print 'Total pairs processed %d' %  count\n",
      "print 'TSS hits %d' % count_TSS_hits\n",
      "print 'No TSS hits %d' % count_no_TSS_hits\n",
      "print 'time taken %s' %(stop-start)\n",
      "\n",
      "\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "'''\n",
      "clustered_region_file = '/global/projectb/projectdirs/PI/Chlamy_Chia_Lin/mouse_ChIA_PET/CAZH/3.map_with_std_bowtie2/bowtie2_map_manual_pair/test_end_to_end_mapping/association_analysis/test/reads_matched_to_clustered_region.txt'\n",
      "count_TSS_hits_in_UR = 0\n",
      "\n",
      "TSS_to_TSS_connection = 0\n",
      "\n",
      "\n",
      "TSS_to_UR_connection = 0\n",
      "\n",
      "for count,row in enumerate(open(clustered_region_file,'r')):\n",
      "    \n",
      "    if count == 100:\n",
      "        pass\n",
      "    \n",
      "    if count == 10000:\n",
      "        print 'processed %d lines' % count\n",
      "    \n",
      "    split_row = row.split('\\t')\n",
      "    \n",
      "    read_header=split_row[3][:-2].strip()\n",
      "    read_type=split_row[3][-1].strip()\n",
      "    \n",
      "    UR_chr=split_row[12].strip()\n",
      "    UR_start=split_row[13].strip()\n",
      "    UR_end=split_row[14].strip()\n",
      "\n",
      "    #print read_header,tss_chr,tss_start,tss_end,read_type\n",
      "    \n",
      "    #new read which was not seen in the TSS data : discard\n",
      "    if read_connections.get(read_header,None) is None:\n",
      "        continue\n",
      "    \n",
      "    \n",
      "    else:\n",
      "    #read was seen in the TSS data\n",
      "    \n",
      "        #TSS-TSS interactions should be captured above\n",
      "        #what would be interesting to look at is the pairs which have one mate in TSS but other in UR (which is not in TSS)\n",
      "        #so any read which already has its two mate accounted for in TSS comparison above is not useful for our comparison\n",
      "        \n",
      "        count_TSS_hits_in_UR += 1\n",
      "        \n",
      "        if len(read_connections[read_header].keys()) == 2:\n",
      "            #i.e both the reads have been seen interacting within a TSS region\n",
      "            #skip\n",
      "            TSS_to_TSS_connection += 1\n",
      "            continue\n",
      "            \n",
      "    \n",
      "        if read_connections[read_header].get(read_type,None) is None:\n",
      "            #found a read whose mate was mapped to TSS and other mate is in the UR region\n",
      "            TSS_to_UR_connection += 1\n",
      "            read_connections[read_header][read_type] = [('UR',UR_chr,UR_start,UR_end)]\n",
      "            \n",
      "        \n",
      "        \n",
      "        #check if the same read was seen or its mate in TSS data\n",
      "        if read_connections[read_header].get(read_type,None) is None:\n",
      "            #only the mate of this read was seen in the TSS data\n",
      "            read_connections[read_header][read_type] = [('UR',UR_chr,UR_start,UR_end)]\n",
      "\n",
      "        \n",
      "    \n",
      "print 'count_TSS_hits_in_UR : %d ' % count_TSS_hits_in_UR\n",
      "print 'count_TSS_to_TSS : %d ' % TSS_to_TSS_connection\n",
      "print 'count_TSS_to_UR : %d ' % TSS_to_UR_connection\n",
      "'''\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}